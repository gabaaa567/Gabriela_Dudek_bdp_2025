{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45986c40-e473-43cc-9f8c-8d6a8af042a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  type                   geometry  sensor_id\n",
      "0  1.0  None  POINT (18.95809 50.27747)          1\n",
      "1  2.0  None  POINT (18.95605 50.27781)          2\n",
      "2  3.0  None  POINT (18.95672 50.28115)          3\n",
      "3  4.0  None   POINT (18.9554 50.28192)          4\n",
      "4  5.0  None   POINT (18.9555 50.27869)          5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# shapefile z czujnikami(sensors)\n",
    "sensors = gpd.read_file(\"C:\\\\Users\\\\User\\\\Desktop\\\\studia_mix\\\\sem_7\\\\bazy_danych_przestrzennych\\\\04_azure_iot\\\\04_iot_data\\\\iot_sensors\\\\iot_sensors\\\\iot_sensors.shp\")\n",
    "\n",
    "\n",
    "sensors[\"sensor_id\"] = pd.to_numeric(sensors[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "sensors = sensors.dropna(subset=[\"sensor_id\"])\n",
    "\n",
    "#konwersja na int\n",
    "sensors[\"sensor_id\"] = sensors[\"sensor_id\"].astype(int)\n",
    "\n",
    "print(sensors.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20f4802-87d6-4add-b279-742e76b08e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK — zapisano 243 predykcji do: C:\\Users\\User\\Desktop\\studia_mix\\sem_7\\bazy_danych_przestrzennych\\04_azure_iot\\04_iot_data\\pred.json\n"
     ]
    }
   ],
   "source": [
    "# spr czy współrzędne są w WGS84 (lon/lat) ---\n",
    "if sensors.crs is None:\n",
    "    sensors = sensors.set_crs(4326)\n",
    "else:\n",
    "    sensors = sensors.to_crs(4326)\n",
    "\n",
    "# precompute lon/lat z geometrii\n",
    "sensors[\"lon\"] = sensors.geometry.x\n",
    "sensors[\"lat\"] = sensors.geometry.y\n",
    "sensors = sensors[[\"sensor_id\", \"lon\", \"lat\"]].copy()\n",
    "\n",
    "\n",
    "READINGS_JSON = r\"C:\\Users\\User\\Desktop\\studia_mix\\sem_7\\bazy_danych_przestrzennych\\04_azure_iot\\04_iot_data\\device_readings.json\"\n",
    "with open(READINGS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "preds = []\n",
    "EPS = 1e-6       \n",
    "MAX_DIST = None\n",
    "\n",
    "for entry in data:\n",
    "    df = pd.DataFrame(entry[\"readings\"])\n",
    "    if df.empty:\n",
    "        preds.append({\"timestamp\": entry[\"timestamp\"], \"position\": None})\n",
    "        continue\n",
    "\n",
    "    df[\"sensor_id\"] = df[\"sensor_id\"].astype(int)\n",
    "\n",
    "    df = df.merge(sensors, on=\"sensor_id\", how=\"inner\")\n",
    "\n",
    "    if df.empty:\n",
    "        preds.append({\"timestamp\": entry[\"timestamp\"], \"position\": None})\n",
    "        continue\n",
    "\n",
    "    # wagi odwrotne do odległości\n",
    "    w = 1.0 / (df[\"distance_m\"].values + EPS)\n",
    "    w_sum = w.sum()\n",
    "\n",
    "    # średnia ważona współrzędnych (x=lon, y=lat)\n",
    "    lon_pred = float((df[\"lon\"].values * w).sum() / w_sum)\n",
    "    lat_pred = float((df[\"lat\"].values * w).sum() / w_sum)\n",
    "\n",
    "    preds.append({\n",
    "        \"timestamp\": entry[\"timestamp\"],\n",
    "        \"position\": {\"lat\": lat_pred, \"lon\": lon_pred}\n",
    "    })\n",
    "\n",
    "\n",
    "OUT_JSON = r\"C:\\Users\\User\\Desktop\\studia_mix\\sem_7\\bazy_danych_przestrzennych\\04_azure_iot\\04_iot_data\\pred.json\"\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(preds, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"OK — zapisano {len(preds)} predykcji do: {OUT_JSON}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95569634-ec3f-4d1c-ae91-2dd3e0a44da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zapisano 486 rekordów do bazy postgres.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# dane połączenia z Azure \n",
    "#usuniete, bo juz polaczone \n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{USER}:{PWD}@{HOST}:{PORT}/{DB}\")\n",
    "\n",
    "\n",
    "PATH = r\"C:\\\\Users\\\\User\\\\Desktop\\\\studia_mix\\\\sem_7\\\\bazy_danych_przestrzennych\\\\04_azure_iot\\\\04_iot_data\\\\pred.json\"\n",
    "with open(PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "for p in data:\n",
    "    if p[\"position\"] is not None:\n",
    "        rows.append({\n",
    "            \"ts\": p[\"timestamp\"],\n",
    "            \"lat\": p[\"position\"][\"lat\"],\n",
    "            \"lon\": p[\"position\"][\"lon\"]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df.to_sql(\"predictions\", engine, if_exists=\"append\", index=False)\n",
    "print(f\"✅ Zapisano {len(df)} rekordów do bazy {DB}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
